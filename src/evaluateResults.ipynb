{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f2ca7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluateResults import getExampleRuntimes, getModelTestResults\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pint import UnitRegistry\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345d5b4",
   "metadata": {},
   "source": [
    "Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e140ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 1\n",
    "\n",
    "with open(\"../evaluation/titles.json\", \"r\") as f:\n",
    "    import json \n",
    "    exTitles = tuple(json.load(f))\n",
    "\n",
    "with open(f\"../info{TEST_NUM}.json\", \"r\") as f:\n",
    "    testInfo = json.load(f)\n",
    "    testTaskIsFast = tuple(testInfo[\"choices\"])\n",
    "\n",
    "runtimesBaseline = runtimesFast = np.array(getExampleRuntimes(\"codeFast\"))\n",
    "runtimesSlow = np.array(getExampleRuntimes(\"codeSlow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ec7eae",
   "metadata": {},
   "source": [
    "Table setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59482753",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtCols = []\n",
    "timeCols = []\n",
    "qtyCols = []\n",
    "boolCols = []\n",
    "choiceCols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "620e7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colExTitle = \"ex.title\"\n",
    "colExFast = \"ex.fast.rt (=: bl)\"\n",
    "colExSlow = \"log10(ex.slow.rt / bl)\"\n",
    "\n",
    "txtCols.append(colExTitle)\n",
    "timeCols.append(colExFast)\n",
    "qtyCols.append(colExSlow)\n",
    "\n",
    "exampleDf = pd.DataFrame(\n",
    "    {\n",
    "        colExTitle: exTitles,\n",
    "        colExFast: runtimesFast,\n",
    "        colExSlow: np.log10(runtimesSlow / runtimesBaseline),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "colTestTaskIsFast = \"test1.task.isFast\"\n",
    "\n",
    "boolCols.append(colTestTaskIsFast)\n",
    "\n",
    "testDf = pd.DataFrame(\n",
    "    {colTestTaskIsFast: testTaskIsFast},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17c91353",
   "metadata": {},
   "outputs": [],
   "source": [
    "claudeResults = getModelTestResults(testNum=1, model=\"claude-sonnet-4\")\n",
    "colTest1ClaudeImproved = \"test1.claude4.improved\"\n",
    "colTest1ClaudeRt = \"log10(test1.claude4.rt / bl)\"\n",
    "\n",
    "choiceCols.append(colTest1ClaudeImproved)\n",
    "qtyCols.append(colTest1ClaudeRt)\n",
    "\n",
    "claudeDf = pd.DataFrame(\n",
    "    {\n",
    "        colTest1ClaudeImproved : claudeResults.improvedInfo,\n",
    "        colTest1ClaudeRt : np.log10(claudeResults.runtimes / runtimesBaseline)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7082ceb",
   "metadata": {},
   "source": [
    "Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5428875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrlr}\n",
      "\\toprule\n",
      "\\midrule\n",
      "1 & Ineff. string concat. in loop & \\SI[]{201.5}{\\micro\\second} & \\num{1.89} & \\halfcirc & \\num{0.27} \\\\\n",
      "2 & Reserving vector capacity & \\SI[]{56.8}{\\micro\\second} & \\num{0.69} & \\halfcirc & \\num{-0.77} \\\\\n",
      "3 & Excessive stream flushing & \\SI[]{501.1}{\\micro\\second} & \\num{0.99} & \\emptycirc & \\num{0.01} \\\\\n",
      "4 & Passing/returning vector by value & \\SI[]{10.8}{\\micro\\second} & \\num{0.00} & \\halfcirc & \\num{-0.47} \\\\\n",
      "5 & Repeated lookups with std::find & \\SI[]{624.8}{\\micro\\second} & \\num{0.17} & \\fullcirc & \\num{-0.05} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ureg = UnitRegistry()\n",
    "\n",
    "def fmtChoice(x : Literal[\"y\", \"n\", \"~\"]) -> str:\n",
    "    match x:\n",
    "        case \"y\": return r\"\\fullcirc\"\n",
    "        case \"n\": return r\"\\emptycirc\"\n",
    "        case \"~\": return r\"\\halfcirc\"\n",
    "        case _: raise ValueError\n",
    "\n",
    "\n",
    "fmt = {\n",
    "    \"txt\": lambda x: x,\n",
    "    \"time\": lambda t: \"{q:.1f~#Lx}\".format(q=ureg.Quantity(t, ureg.second)),\n",
    "    \"qty\": lambda x: r\"\\num{\" + f\"{x:.2f}\" + r\"}\",\n",
    "    \"choice\": fmtChoice,\n",
    "}\n",
    "\n",
    "fmtMap = {}\n",
    "fmtMap |= dict.fromkeys(txtCols, fmt[\"txt\"])\n",
    "fmtMap |= dict.fromkeys(timeCols, fmt[\"time\"])\n",
    "fmtMap |= dict.fromkeys(qtyCols, fmt[\"qty\"])\n",
    "fmtMap |= dict.fromkeys(choiceCols, fmt[\"choice\"])\n",
    "\n",
    "export = pd.concat((exampleDf, claudeDf), axis=1).head()\n",
    "export.index += 1\n",
    "print(export.to_latex(\n",
    "    header=False,\n",
    "    formatters=fmtMap,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "412840aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ex.title'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export[colExTitle].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57444b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4fab2cd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a44528a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\cellcolor{red!25}{1}'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"\\cellcolor{red!25}{%(content)s}\" % dict(content=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3db48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
